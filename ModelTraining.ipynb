{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages and libraries\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from statistics import mean\n",
    "import pickle\n",
    "import time\n",
    "from datetime import date, timedelta, datetime\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from functools import lru_cache\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds the binary indicator column and datetime features\n",
    "#Refer the other notebook HHDataAnalysis.ipynb for other funtions used within this function\n",
    "\n",
    "def add_BIcolumn(weather_data):\n",
    "    \n",
    "    df = weather_data.copy()\n",
    "    df['datetime'] =  df.index.copy()\n",
    "    df['month'] =   df['datetime'].dt.month\n",
    "    df['dayofmonth'] =   df['datetime'].dt.day\n",
    "    df['hour'] =   df['datetime'].dt.hour\n",
    "    df['minute'] =   df['datetime'].dt.minute\n",
    "    latitude = 50.93\n",
    "    longitude = 5.33\n",
    "    df['LDI'] = 0\n",
    "    start = df.index.min().date()\n",
    "    end = df.index.max().date()\n",
    "#     print(start, end)\n",
    "    \n",
    "    for date1 in pd.date_range(start, end, freq='D'):\n",
    "        sunrise, sunset = get_sunrise_sunset(latitude, longitude, date1)\n",
    "        range_start = pd.to_datetime(datetime.combine(date1, sunrise.time()))\n",
    "        range_end = pd.to_datetime(datetime.combine(date1, sunset.time()))\n",
    "        df.loc[(df.index > range_start) & (df.index < range_end), 'LDI'] = 1\n",
    "        \n",
    "    df = df.drop(['datetime'], axis =1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds the lagged variables based on the finding from the autocorrelation plots as shown in HHDataAnalysis.ipynb\n",
    "\n",
    "def add_lagged(df):\n",
    "    \n",
    "    df1=df.copy()    \n",
    "    \n",
    "    prev1 = df1['negative_active_energy_flow_wh'].shift(96, fill_value=0)\n",
    "    prev2 = df1['negative_active_energy_flow_wh'].shift(192, fill_value=0)\n",
    "    prev3 = df1['negative_active_energy_flow_wh'].shift(288, fill_value=0)\n",
    "#     prev4 = df1['negative_active_energy_flow_wh'].shift(384, fill_value=0)\n",
    "    \n",
    "    prev_mean = df1['negative_active_energy_flow_wh'].rolling(3).mean()\n",
    "    \n",
    "    df1.insert(loc=0, column='prev1', value= prev1)\n",
    "    df1.insert(loc=1, column='prev2', value= prev2)\n",
    "    df1.insert(loc=2, column='prev3', value= prev3)\n",
    "#     df1.insert(loc=3, column='prev4', value= prev4)\n",
    "\n",
    "    df1.insert(loc=3, column = 'prev1_mean', value = prev_mean.shift(96, fill_value=0))  \n",
    "    df1.insert(loc=4, column = 'prev2_mean', value = prev_mean.shift(192, fill_value=0))\n",
    "    df1.insert(loc=5, column = 'prev3_mean', value = prev_mean.shift(288, fill_value=0))\n",
    "    \n",
    "    df2 = pd.DataFrame(df1[288:])\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preps the data to be fed into the models and replaces missing and negative entries\n",
    "\n",
    "def prep_pv_data(HH_data, weather_data):\n",
    "    \n",
    "    hh_data = HH_data.copy()\n",
    "    hh_data = hh_data[hh_data.index.isin(weather_data.index)]\n",
    "    hh_data['LDI'] = weather_data['LDI']\n",
    "    hh_data['datetime'] = hh_data.index.copy()\n",
    "    hh_data['month'] =  hh_data['datetime'].dt.month\n",
    "    hh_data['hour'] =  hh_data['datetime'].dt.hour\n",
    "    hh_data =  hh_data.drop_duplicates('datetime', keep='last')\n",
    "    \n",
    "    for i in range(len(hh_data)):\n",
    "        if hh_data['LDI'][i] == 0:\n",
    "            hh_data['negative_active_energy_flow_wh'][i] = 0 \n",
    "    \n",
    "    missing = hh_data[hh_data['negative_active_energy_flow_wh'].isnull()]\n",
    "    for i in range(len(missing)):\n",
    "        target_month = missing.index[i].month\n",
    "        target_hour = missing.index[i].hour\n",
    "        temp_hh = hh_data[~hh_data.index.isin(missing.index)]\n",
    "        temp = temp_hh[(temp_hh['month']==target_month)& (temp_hh['hour']==target_hour)]\n",
    "        missing['negative_active_energy_flow_wh'][i] = temp['negative_active_energy_flow_wh'].mean()\n",
    "    \n",
    "    hh_data.loc[hh_data.index.isin(missing.index) , 'negative_active_energy_flow_wh'] = missing['negative_active_energy_flow_wh']\n",
    "    \n",
    "    neg = hh_data[hh_data['negative_active_energy_flow_wh']<0]\n",
    "    for i in range(len(neg)):\n",
    "        target_month1 = neg.index[i].month\n",
    "        target_hour1 = neg.index[i].hour         \n",
    "        temp_hh1 = hh_data[~hh_data.index.isin(neg.index)]\n",
    "        temp1 = temp_hh1[(temp_hh1['month']==target_month1)& ( temp_hh1['hour']==target_hour1)]\n",
    "        neg['negative_active_energy_flow_wh'][i] = temp1['negative_active_energy_flow_wh'].mean()\n",
    "\n",
    "    hh_data.loc[hh_data.index.isin(neg.index) , 'negative_active_energy_flow_wh'] = neg['negative_active_energy_flow_wh']\n",
    "    \n",
    "    hh_data = hh_data.drop(['datetime', 'hour', 'month', 'LDI'], axis =1)\n",
    "    hh_data = hh_data.fillna(0)\n",
    "    hh_data = hh_data.clip(0)\n",
    "    hh_data = hh_data.round(2)\n",
    "        \n",
    "    return hh_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper funtion that combines all of the above, removes features based off the baseline results and saves past data needed for training/testing and the \n",
    "#future data that be used as unseen data to assess how well each model can predict\n",
    "\n",
    "def prep_model_data(split):\n",
    "    \n",
    "    esf, hh, wd = prepDatasets()\n",
    "    wd_new = add_BIcolumn(wd)\n",
    "    hh1 = prep_pv_data(hh, wd_new)\n",
    "    hh_new = add_lagged(hh1)\n",
    "    \n",
    "    ESF = esf[esf.index.isin(hh_new.index)]\n",
    "    WD = wd_new[wd_new.index.isin(hh_new.index)]\n",
    "    df1 = WD.join(ESF)\n",
    "    ModelData = df1.join(hh_new)\n",
    "\n",
    "    ModelData.replace([np.inf, -np.inf], np.nan)  \n",
    "    ModelData = ModelData.fillna(0)\n",
    "    ModelData = ModelData.clip(0)\n",
    "    ModelData = ModelData.round(2)\n",
    "    \n",
    "    Model_data = ModelData.loc[(ModelData.index < '2022-07-15')]    \n",
    "    #Features removed based on regression coefficients\n",
    "    Model_data = Model_data.drop(['HCC', 'MCC', 'TCC', 'TP', 'WS', 'hour', 'minute'], axis=1)\n",
    "    \n",
    "    past = Model_data[:split]\n",
    "    future = Model_data[split:] \n",
    "    \n",
    "    past.to_csv('past_new.csv')\n",
    "    future.to_csv('future_new.csv')\n",
    "    \n",
    "    return past, future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that fetches past and future data\n",
    "\n",
    "def get_data():\n",
    "    \n",
    "    past = pd.read_csv('past_new.csv')\n",
    "    past.set_index('valid_datetime', drop=True, inplace=True)\n",
    "    past.index = pd.to_datetime(past.index)\n",
    "    \n",
    "    future = pd.read_csv('future_new.csv')\n",
    "    future.set_index('valid_datetime', drop=True, inplace=True)\n",
    "    future.index = pd.to_datetime(future.index)\n",
    "    \n",
    "    return past, future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to normalize the training data using the specified scaler and reshape it according to the expected model input shape\n",
    "\n",
    "def prep_train(train, scaler_type, timesteps, is3D = True):\n",
    "    \n",
    "    if scaler_type == 'std':\n",
    "        scaler_x = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler_x = MinMaxScaler(feature_range=(0, 1))  \n",
    "        scaler_y = MinMaxScaler(feature_range=(0, 1))  \n",
    "    \n",
    "    train_X, train_y = np.array(train.iloc[:, :-1]), np.array(train.iloc[:, -1]).reshape(-1, 1)\n",
    "    \n",
    "    X_transformer = scaler_x.fit(train_X)\n",
    "    y_transformer = scaler_y.fit(train_y)\n",
    "    \n",
    "    if is3D:\n",
    "        X_train_F = X_transformer.fit_transform(train_X).reshape((train_X.shape[0], timesteps, train_X.shape[1]))\n",
    "    else:\n",
    "        X_train_F = X_transformer.fit_transform(train_X).reshape((train_X.shape[0], train_X.shape[1]))\n",
    "        \n",
    "    y_train_F = y_transformer.fit_transform(train_y)\n",
    "    \n",
    "    return X_transformer, y_transformer, X_train_F, y_train_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that normalizes and reshapes the testing data\n",
    "\n",
    "def transform(X_transformer, data, timesteps, is3D = True):\n",
    "    \n",
    "    data_X = np.array(data.iloc[:, :-1])\n",
    "    \n",
    "    if is3D:\n",
    "        X_data_F = X_transformer.transform(data_X).reshape((timesteps, data_X.shape[0],data_X.shape[1]))\n",
    "    else:\n",
    "        X_data_F = X_transformer.transform(data_X).reshape((data_X.shape[0], data_X.shape[1]))\n",
    "        \n",
    "    return X_data_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(X_train, y_train, subsequence_size):\n",
    "    X , y = [], []\n",
    "    stop = len(X_train)-subsequence_size + 1\n",
    "    for i in range(0, stop) :\n",
    "        end_ix = i + subsequence_size\n",
    "        seq_x, seq_y = X_train[i:end_ix , :], y_train[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to run the baseline model, obtain the regression coefficient values with respect to each feature and genertae test results\n",
    "\n",
    "def run_baseline(scaler ='std', split = -1344, forecast_horizon=96):\n",
    "    \n",
    "    past, future = get_data()\n",
    "    \n",
    "#     past = past.drop(['HCC', 'MCC', 'TCC', 'TP', 'WS', 'LDI', 'hour', 'minute', 'prev4'], axis=1)\n",
    "\n",
    "    train = past[:split]\n",
    "    test = past[split:]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    name = ['LinReg1']\n",
    "    \n",
    "    test_results = pd.DataFrame()\n",
    "    coefficients = pd.DataFrame(columns = ['feature', 'coefficient'])\n",
    "    coefficients['feature'] = train.columns\n",
    "    \n",
    "    final_mape =[]\n",
    "    final_mse = []\n",
    "    r2_scores = []\n",
    "    Adj_r2 =[]\n",
    "    predictions= []    \n",
    "    \n",
    "    X_transformer, y_transformer, X_train, y_train =  prep_train(train, scaler, timesteps =1, is3D = False)\n",
    "    reg = model.fit(X_train, y_train)\n",
    "    print(f\"coef: {reg.coef_}\")\n",
    "    coefficients['coefficient'][:-1] = reg.coef_[0]\n",
    "    for i in range(0, abs(split)-95, 1):\n",
    "        new_test = test.iloc[i:i+forecast_horizon,:]\n",
    "        output = pd.DataFrame(index = new_test.index, columns = ['true', 'pred'])\n",
    "        X_test = transform(X_transformer,new_test, timesteps=1, is3D = False)        \n",
    "        y_pred = reg.predict(X_test)\n",
    "        yhat1 = y_transformer.inverse_transform(y_pred.reshape(-1,1))\n",
    "        yhatf = np.clip(yhat1,0, 10000)\n",
    "        predictions.extend(yhatf[0])\n",
    "    \n",
    "        rmse = math.sqrt(mean_squared_error(new_test.iloc[:, -1], yhatf))\n",
    "        r2 = r2_score(new_test.iloc[:, -1], yhatf)\n",
    "        adj_r2 = 1-((1-r2)* (len(new_test)-1)/(len(new_test)-len(train.columns)-1))\n",
    "        final_mse.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        Adj_r2.append(adj_r2)\n",
    "        output['true'] = new_test.iloc[:, -1]\n",
    "        output['pred'] = yhatf\n",
    "        non_zero = new_test[new_test['negative_active_energy_flow_wh'] != 0]\n",
    "        non_zero_pred = output[output.index.isin(non_zero.index)]\n",
    "        mape = mean_absolute_percentage_error(non_zero_pred['true'], non_zero_pred['pred'])\n",
    "        final_mape.append(mape)\n",
    "    \n",
    "    test_results['model'] = name\n",
    "    test_results['test_mape'] = round(mean(final_mape),3)\n",
    "    test_results['test_rmse'] = round(mean(final_mse),3)\n",
    "    test_results['test_r2_score'] = round(mean(r2_scores),3)\n",
    "    test_results['test_adj_r2_score'] = round(mean(Adj_r2),3)\n",
    "    \n",
    "    display(coefficients)\n",
    "    display(test_results)\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates all combinations of hyperparameters for the LSTM model\n",
    "def lstm_configs():\n",
    "    n_nodes_l1 = [25]\n",
    "    n_nodes_l2 = [10]\n",
    "    dropout = [0.2, 0.3, 0.4]\n",
    "    lr = [0.001, 0.0001, 0.00001]\n",
    "    n_epochs = [50, 100, 300]\n",
    "    batch_size = [32, 64, 128]\n",
    "    configs = list()\n",
    "    for j in n_nodes_l1:\n",
    "        for k in n_nodes_l2:\n",
    "            for l in dropout:\n",
    "                for m in lr:\n",
    "                    for n in n_epochs:\n",
    "                        for p in batch_size:\n",
    "                            cfg = [j, k, l, m, n, p]\n",
    "                            configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "#Creates simple LSTM model with one hidden layer\n",
    "def LSTM_model(X_train, config):\n",
    "    optimizer = SGD(learning_rate=config[3])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(config[0], input_shape =(X_train.shape[1], X_train.shape[2]), return_sequences = True))\n",
    "    model.add((LSTM(config[1], activation='elu', kernel_initializer=\"he_normal\", return_sequences = True)))\n",
    "    model.add(Dropout(config[2]))\n",
    "    model.add(Dense(1, activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    model.build(input_shape= X_train.shape)\n",
    "    model.summary()\n",
    "\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates all combinations of hyperparameters for the CNN model\n",
    "def cnn_configs():\n",
    "    n_filters_l1 = [32]\n",
    "    n_filters_l2 = [16]\n",
    "    kernel_size = [1]\n",
    "    dropout = [0.2, 0.3, 0.4]\n",
    "    lr = [0.001, 0.0001, 0.00001]\n",
    "    n_epochs = [50, 100, 300]\n",
    "    batch_size = [32, 64, 128]\n",
    "    configs = list()\n",
    "    for j in n_filters_l1:\n",
    "        for k in n_filters_l2:\n",
    "            for m in kernel_size:\n",
    "                for p in dropout:\n",
    "                    for q in lr:\n",
    "                        for r in n_epochs:\n",
    "                            for s in batch_size:\n",
    "                                cfg = [j, k, m, p, q,r,s]\n",
    "                                configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "\n",
    "#Creates simple CNN model with one hidden layer\n",
    "def CNN_model(X_train, config):\n",
    "    optimizer = SGD(learning_rate=config[4])\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters= config[0], kernel_size= config[2], input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "              activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2, padding = 'same'))\n",
    "    model.add(Conv1D(filters= config[1], kernel_size=config[2], activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(config[3]))\n",
    "    model.add(Dense(X_train.shape[1],activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    model.build(input_shape= X_train.shape)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates all combinations of hyperparameters for the CNN-LSTM model\n",
    "def cnn_lstm_configs():\n",
    "    conv_filters_l1 = [16]\n",
    "    kernel_size = [1]\n",
    "    lstm_nodes_l1 = [10]\n",
    "    dropout = [0.2, 0.3, 0.4]\n",
    "    lr = [0.001]\n",
    "    n_epochs = [50, 100, 300]\n",
    "    batch_size = [32, 64, 128]\n",
    "    configs = list()\n",
    "    for j in conv_filters_l1:\n",
    "        for k in kernel_size:\n",
    "            for l in lstm_nodes_l1:\n",
    "                for m in dropout:\n",
    "                    for n in lr:\n",
    "                        for p in n_epochs:\n",
    "                            for q in batch_size:\n",
    "                                cfg = [j, k, l, m, n, p, q]\n",
    "                                configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "#Creates simple CNN-LSTM model with one CNN and one LSTM layer\n",
    "def CNN_LSTM_model(X_train, config):\n",
    "    optimizer = SGD(learning_rate=config[4])\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=config[0], kernel_size=config[1], input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "              activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.add(LSTM(config[2], activation='elu', kernel_initializer=\"he_normal\", return_sequences = True))\n",
    "    model.add(Dropout(config[3]))\n",
    "    model.add(Dense(1, activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    model.build(input_shape= X_train.shape)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates all combinations of shortlisted hyperparameters for the LSTM model based on the first round of training and testing\n",
    "def new_lstm_configs():\n",
    "    n_nodes_l1 = [50]\n",
    "    n_nodes_l2 = [25]\n",
    "    n_nodes_l3 = [10]\n",
    "    dropout = [0.3, 0.4]\n",
    "    lr = [0.01, 0.0001]\n",
    "    n_epochs = [300]\n",
    "    batch_size = [32]\n",
    "    configs = list()\n",
    "    for j in n_nodes_l1:\n",
    "        for k in n_nodes_l2:\n",
    "            for q in n_nodes_l3:\n",
    "                for l in dropout:\n",
    "                    for m in lr:\n",
    "                        for n in n_epochs:\n",
    "                            for p in batch_size:\n",
    "                                cfg = [j, k, q, l, m, n, p]\n",
    "                                configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "# Function used to test with a LSTM model with no/two hidden layers\n",
    "def new_LSTM_model(X_train, config):\n",
    "    optimizer = SGD(learning_rate=config[4])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(config[0], input_shape =(X_train.shape[1], X_train.shape[2]), return_sequences = True))\n",
    "    model.add((LSTM(config[1], activation='elu', kernel_initializer=\"he_normal\", return_sequences = True)))\n",
    "    model.add((LSTM(config[2], activation='elu', kernel_initializer=\"he_normal\", return_sequences = True)))\n",
    "    model.add(Dropout(config[3]))\n",
    "    model.add(Dense(1, activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    model.build(input_shape= X_train.shape)\n",
    "    model.summary()\n",
    "\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generates all combinations of shortlisted hyperparameters for the CNN model based on the first round of training and testing\n",
    "def new_cnn_configs():\n",
    "    n_filters_l1 = [64]\n",
    "    n_filters_l2 = [32]\n",
    "    n_filters_l3 = [16]\n",
    "    kernel_size = [1, 2]\n",
    "    dropout = [0.3, 0.4]\n",
    "    lr = [0.01, 0.001]\n",
    "    n_epochs = [300]\n",
    "    batch_size = [32]\n",
    "    configs = list()\n",
    "    for j in n_filters_l1:\n",
    "        for k in n_filters_l2:\n",
    "            for l in n_filters_l3:\n",
    "                for m in kernel_size:\n",
    "                    for p in dropout:\n",
    "                        for q in lr:\n",
    "                            for r in n_epochs:\n",
    "                                for s in batch_size:\n",
    "                                    cfg = [j, k, l, m, p, q,r,s]\n",
    "                                    configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "# Function used to test with a CNN model with no/two hidden layers\n",
    "def new_CNN_model(X_train, config):\n",
    "    optimizer = SGD(learning_rate=config[5])\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters= config[0], kernel_size = config[3], input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "              activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2, padding = 'same'))\n",
    "    model.add(Conv1D(filters= config[1], kernel_size=config[3], activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2, padding = 'same'))\n",
    "    model.add(Conv1D(filters= config[2], kernel_size=config[3], activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(config[4]))\n",
    "    model.add(Dense(X_train.shape[1],activation='elu', kernel_initializer=\"he_normal\"))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    model.build(input_shape= X_train.shape)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to run the LSTM model and generate test results\n",
    "def run_LSTM_15(model, config, scaler = 'std', split= -1344, forecast_horizon =96 , is3D = True):\n",
    "    \n",
    "    past, future = get_data()\n",
    "    \n",
    "    train = past[:split]\n",
    "    test = past[split:]\n",
    "\n",
    "    test_results = pd.DataFrame()\n",
    "    layer1_neurons =[]\n",
    "    layer2_neurons = []\n",
    "    layer3_neurons =[]\n",
    "    dropout = []\n",
    "    learning_rate =[]\n",
    "    n_epochs = []\n",
    "    batch_size = []\n",
    "    final_mape =[]\n",
    "    final_rmse = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    layer1_neurons.append(config[0])\n",
    "    layer2_neurons.append(config[1])\n",
    "    layer3_neurons.append(config[2])\n",
    "    dropout.append(config[3])\n",
    "    learning_rate.append(config[4])\n",
    "    n_epochs.append(config[5])\n",
    "    batch_size.append(config[6])\n",
    "\n",
    "    X_transformer, y_transformer, X_train, y_train =  prep_train(past, scaler, timesteps = 1, is3D =is3D)\n",
    "    reg = fit_NNmodel(X_train, y_train, model, config, forecast_horizon= forecast_horizon)\n",
    "    RMSE =[]\n",
    "    MAPE=[]\n",
    "    R2 = []\n",
    "    for i in range(0, abs(split)-forecast_horizon, 1): \n",
    "        new_test = test.iloc[i:i+forecast_horizon,:]\n",
    "        output = pd.DataFrame(index = new_test.index, columns = ['true', 'pred'])\n",
    "        X_test = transform(X_transformer,new_test, timesteps=1, is3D = is3D)          \n",
    "        y_pred = reg.predict(X_test)\n",
    "        yhat1 = y_transformer.inverse_transform(y_pred.reshape(-1,1))\n",
    "        yhatf = np.clip(yhat1,0, 10000)\n",
    "\n",
    "        rmse = math.sqrt(mean_squared_error(new_test.iloc[:, -1], yhatf))\n",
    "        RMSE.append(rmse)\n",
    "        r2 = r2_score(new_test.iloc[:, -1], yhatf)\n",
    "        R2.append(r2)\n",
    "        output['true'] = new_test.iloc[:, -1]\n",
    "        output['pred'] = yhatf \n",
    "        non_zero = new_test[new_test['negative_active_energy_flow_wh'] != 0]\n",
    "        non_zero_pred = output[output.index.isin(non_zero.index)]\n",
    "        mape = mean_absolute_percentage_error(non_zero_pred['true'], non_zero_pred['pred'])\n",
    "        MAPE.append(mape)\n",
    "\n",
    "    final_mape.append(round(mean(MAPE),3))\n",
    "    final_rmse.append(round(mean(RMSE),3))\n",
    "    r2_scores.append(round(mean(R2),3))\n",
    "        \n",
    "    test_results['layer1_neurons'] = layer1_neurons\n",
    "    test_results['layer2_neurons'] = layer2_neurons\n",
    "    test_results['layer3_neurons'] = layer3_neurons\n",
    "    test_results['dropout'] = dropout\n",
    "    test_results['learning_rate'] = learning_rate\n",
    "    test_results['n_epochs'] = n_epochs\n",
    "    test_results['batch_size'] = batch_size\n",
    "    test_results['test_mape'] = final_mape\n",
    "    test_results['test_rmse'] = final_rmse\n",
    "    test_results['test_r2_score'] = r2_scores\n",
    "\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to run the CNN model and generate test results\n",
    "def run_CNN_15(model, config, scaler = 'std', split= -1344, forecast_horizon =96 , is3D = True):\n",
    "    \n",
    "    past, future = get_data()\n",
    "    \n",
    "    train = past[:split]\n",
    "    test = past[split:]\n",
    "\n",
    "    test_results = pd.DataFrame()\n",
    "    layer1_filters =[]\n",
    "    layer2_filters = []\n",
    "    layer3_filters = []\n",
    "    kernel_size = []\n",
    "    dropout = []\n",
    "    learning_rate =[]\n",
    "    n_epochs = []\n",
    "    batch_size = []\n",
    "    final_mape =[]\n",
    "    final_rmse = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    print(config)\n",
    "    \n",
    "    layer1_filters.append(config[0])\n",
    "    layer2_filters.append(config[1])\n",
    "    layer3_filters.append(config[2])\n",
    "    kernel_size.append(config[3])\n",
    "    dropout.append(config[4])\n",
    "    learning_rate.append(config[5])\n",
    "    n_epochs.append(config[6])\n",
    "    batch_size.append(config[7])\n",
    "\n",
    "    X_transformer, y_transformer, X_train, y_train =  prep_train(past, scaler, timesteps = 1, is3D =is3D)\n",
    "    reg = fit_NNmodel(X_train, y_train, model, config, forecast_horizon= forecast_horizon)\n",
    "    RMSE =[]\n",
    "    MAPE=[]\n",
    "    R2 = []\n",
    "    for i in range(0, abs(split)-forecast_horizon, 1):\n",
    "        new_test = test.iloc[i:i+forecast_horizon,:]\n",
    "        output = pd.DataFrame(index = new_test.index, columns = ['true', 'pred'])\n",
    "        X_test = transform(X_transformer,new_test, timesteps=1, is3D = is3D)          \n",
    "        y_pred = reg.predict(X_test)\n",
    "        yhat1 = y_transformer.inverse_transform(y_pred.reshape(-1,1))\n",
    "        yhatf = np.clip(yhat1,0, 10000)\n",
    "\n",
    "        rmse = math.sqrt(mean_squared_error(new_test.iloc[:, -1], yhatf))\n",
    "        RMSE.append(rmse)\n",
    "        r2 = r2_score(new_test.iloc[:, -1], yhatf)\n",
    "        R2.append(r2)\n",
    "        output['true'] = new_test.iloc[:, -1]\n",
    "        output['pred'] = yhatf \n",
    "        non_zero = new_test[new_test['negative_active_energy_flow_wh'] != 0]\n",
    "        non_zero_pred = output[output.index.isin(non_zero.index)]\n",
    "        mape = mean_absolute_percentage_error(non_zero_pred['true'], non_zero_pred['pred'])\n",
    "        MAPE.append(mape)\n",
    "    \n",
    "    final_mape.append(round(mean(MAPE),3))\n",
    "    final_rmse.append(round(mean(RMSE),3))\n",
    "    r2_scores.append(round(mean(R2),3))\n",
    "        \n",
    "    test_results['layer1_filters'] = layer1_filters\n",
    "    test_results['layer2_filters'] =  layer2_filters\n",
    "    test_results['layer3_filters'] =  layer3_filters\n",
    "    test_results['kernel_size'] =  kernel_size\n",
    "    test_results['dropout'] = dropout\n",
    "    test_results['learning_rate'] = learning_rate\n",
    "    test_results['n_epochs'] = n_epochs\n",
    "    test_results['batch_size'] = batch_size\n",
    "    test_results['test_mape'] = final_mape\n",
    "    test_results['test_rmse'] = final_rmse\n",
    "    test_results['test_r2_score'] = r2_scores\n",
    "\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to run the CNN-LSTM model and generate test results\n",
    "def run_CNN_LSTM_15(model, config, scaler = 'std', split= -1344, forecast_horizon=96 , is3D = True):\n",
    "    \n",
    "    past, future = get_data()\n",
    "    \n",
    "    train = past[:split]\n",
    "    test = past[split:]\n",
    "\n",
    "    test_results = pd.DataFrame()\n",
    "    conv_filters_l1 = []\n",
    "    kernel_size = []\n",
    "    lstm_nodes_l1 = []\n",
    "    dropout = []\n",
    "    learning_rate =[]\n",
    "    n_epochs = []\n",
    "    batch_size = []\n",
    "    final_mape =[]\n",
    "    final_rmse = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    print(config)\n",
    "    \n",
    "    conv_filters_l1.append(config[0])\n",
    "    kernel_size.append(config[1])\n",
    "    lstm_nodes_l1.append(config[2])\n",
    "    dropout.append(config[3])\n",
    "    learning_rate.append(config[4])\n",
    "    n_epochs.append(config[5])\n",
    "    batch_size.append(config[6])\n",
    "\n",
    "    X_transformer, y_transformer, X_train, y_train =  prep_train(past, scaler, timesteps = 1, is3D =is3D)\n",
    "    n_features, reg = fit_NNmodel(X_train, y_train, model, config, forecast_horizon= forecast_horizon)\n",
    "    RMSE =[]\n",
    "    MAPE=[]\n",
    "    R2 = []\n",
    "    for i in range(0, abs(split)-forecast_horizon, 1):\n",
    "        new_test = test.iloc[i:i+forecast_horizon,:]\n",
    "        output = pd.DataFrame(index = new_test.index, columns = ['true', 'pred'])\n",
    "        X_test = transform(X_transformer,new_test, timesteps=1, is3D = is3D)          \n",
    "        y_pred = reg.predict(X_test)\n",
    "        yhat1 = y_transformer.inverse_transform(y_pred.reshape(-1,1))\n",
    "        yhatf = np.clip(yhat1,0, 10000)\n",
    "\n",
    "        rmse = math.sqrt(mean_squared_error(new_test.iloc[:, -1], yhatf))\n",
    "        RMSE.append(rmse)\n",
    "        r2 = r2_score(new_test.iloc[:, -1], yhatf)\n",
    "        R2.append(r2)\n",
    "        output['true'] = new_test.iloc[:, -1]\n",
    "        output['pred'] = yhatf \n",
    "        non_zero = new_test[new_test['negative_active_energy_flow_wh'] != 0]\n",
    "        non_zero_pred = output[output.index.isin(non_zero.index)]\n",
    "        mape = mean_absolute_percentage_error(non_zero_pred['true'], non_zero_pred['pred'])\n",
    "        MAPE.append(mape)\n",
    "\n",
    "    final_mape.append(round(mean(MAPE),3))\n",
    "    final_rmse.append(round(mean(RMSE),3))\n",
    "    r2_scores.append(round(mean(R2),3))\n",
    "        \n",
    "    test_results['conv_filters_l1'] = conv_filters_l1\n",
    "    test_results['kernel_size'] =  kernel_size\n",
    "    test_results['lstm_nodes_l1'] =  lstm_nodes_l1\n",
    "    test_results['dropout'] = dropout\n",
    "    test_results['learning_rate'] = learning_rate\n",
    "    test_results['n_epochs'] = n_epochs\n",
    "    test_results['batch_size'] = batch_size\n",
    "    test_results['test_mape'] = final_mape\n",
    "    test_results['test_rmse'] = final_rmse\n",
    "    test_results['test_r2_score'] = r2_scores\n",
    "\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to return the specified neural network model fitted to the train data\n",
    "def fit_NNmodel(X_train, y_train, model, config, forecast_horizon= 96):\n",
    "    \n",
    "    n_features = X_train.shape[-1]\n",
    "    print(n_features)\n",
    "    \n",
    "    n_epochs = config[-2]\n",
    "    batchsize = config[-1]\n",
    "    \n",
    "#     #used only during prediction \n",
    "#     n_epochs = 300\n",
    "#     batchsize = 32\n",
    "    \n",
    "    X_train, y_train= split_sequences(X_train, y_train, 96)\n",
    "    print('1', X_train.shape)\n",
    "    print('2', y_train.shape)\n",
    "    \n",
    "    if model == 'lstm':\n",
    "        X_train = X_train.reshape(-1, forecast_horizon, n_features)\n",
    "        print('2', X_train.shape)\n",
    "        model = LSTM_model(X_train, config)\n",
    "        model.fit(X_train, y_train, epochs = n_epochs, batch_size=batchsize)\n",
    "    elif model == 'lstm1':\n",
    "        X_train = X_train.reshape(-1, forecast_horizon, n_features)\n",
    "        print('2', X_train.shape)\n",
    "        model = new_LSTM_model(X_train, config)\n",
    "        model.fit(X_train, y_train, epochs = n_epochs, batch_size=batchsize)\n",
    "    elif model == 'cnn':\n",
    "        X_train = X_train.reshape(-1, forecast_horizon, n_features)\n",
    "        print('3', X_train.shape)\n",
    "        model = CNN_model(X_train, config)\n",
    "        model.fit(X_train, y_train, epochs = n_epochs, batch_size=batchsize)\n",
    "    elif model == 'cnn1':\n",
    "        X_train = X_train.reshape(-1, forecast_horizon, n_features)\n",
    "        model = new_CNN_model(X_train, config)\n",
    "        model.fit(X_train, y_train, epochs = n_epochs, batch_size=batchsize)\n",
    "    else:\n",
    "        X_train = X_train.reshape(-1, forecast_horizon, n_features)\n",
    "        model = CNN_LSTM_model(X_train, config)\n",
    "        model.fit(X_train, y_train, epochs = n_epochs, batch_size=batchsize)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_configs = new_lstm_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results were obtained for each config and saved onto a csv file\n",
    "#Same procedure repeated for all models by calling their respective functions in which the code was adapted according to what was included in the configs\n",
    "test_results = run_LSTM_15('lstm1', all_configs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to predict for unseen data and generate pred results and final pred plot\n",
    "def pred_future(model, name, title, scaler ='std', is3D= True):\n",
    "    \n",
    "    past, future = get_data()\n",
    "\n",
    "    display(past)\n",
    "    predictions_future = []\n",
    "    pred_results = pd.DataFrame()\n",
    "    pred_mape =[]\n",
    "    pred_rmse =[]\n",
    "    pred_r2 = []\n",
    "    \n",
    "    X_transformer, y_transformer, X_train, y_train =  prep_train(past, scaler, timesteps = 1, is3D =is3D)\n",
    "    \n",
    "    # baseline model\n",
    "    reg = model.fit(X_train, y_train)\n",
    "    \n",
    "    # for all neural networks, the config value is set to 1 to avoid errors and the actual final choice of hyperparamters were substituted in their respective places in their functions\n",
    "    reg = fit_NNmodel(X_train, y_train, model, config = 1)\n",
    "\n",
    "    for i in range(0, len(future)-95, 1):\n",
    "        future_test = future.iloc[i:i+96,:]\n",
    "        output = pd.DataFrame(index = future_test.index, columns = ['true', 'pred'])\n",
    "        future_X_F = transform(X_transformer, future_test, timesteps=1, is3D = is3D)\n",
    "        y_pred_F = reg.predict(future_X_F)\n",
    "        yhat2 = y_transformer.inverse_transform(y_pred_F.reshape(-1,1))\n",
    "        yhat_F = np.clip(yhat2,0, 10000)\n",
    "        if i != len(future)-96:\n",
    "            predictions_future.extend(yhat_F[0])\n",
    "        else:\n",
    "            for n in range(len(yhat_F)):\n",
    "                predictions_future.extend(yhat_F[n])\n",
    "    \n",
    "        output['true'] = future_test.iloc[:, -1]\n",
    "        output['pred'] = yhat_F\n",
    "        non_zero = future_test[future_test['negative_active_energy_flow_wh'] != 0]\n",
    "        non_zero_future = output[output.index.isin(non_zero.index)]\n",
    "\n",
    "        pred_mape.append(mean_absolute_percentage_error(non_zero_future['true'], non_zero_future['pred']))\n",
    "        pred_rmse.append(math.sqrt(mean_squared_error(future_test.iloc[:, -1], yhat_F)))\n",
    "        pred_r2.append(r2_score(future_test.iloc[:, -1].clip(0), yhat_F))\n",
    "\n",
    "    pred_results['model'] = name\n",
    "    pred_results['pred_mape'] = round(mean(pred_mape),3)\n",
    "    pred_results['pred_rmse'] = round(mean(pred_rmse),3)\n",
    "    pred_results['pred_r2_score'] = round(mean(pred_r2),3)\n",
    "    \n",
    "    fig = plot_pred(future.index, future.iloc[:, -1], predictions_future, title = title)\n",
    "    \n",
    "    return pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how pred results were generated for the final LSTM model\n",
    "pred_results = pred_future(model = 'lstm1', name = ['LSTM'] , title = 'LSTM Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
